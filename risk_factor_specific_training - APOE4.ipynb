{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ccb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import ttest_ind\n",
    "import joblib\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57033a3c-e675-4b1c-8236-aab049c63bf5",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cfea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_seed=42\n",
    "np.random.seed(splitting_seed)\n",
    "top_age=75# chaning this metric changes the upper bound of the target region\n",
    "Num_models=25\n",
    "\n",
    "#######\n",
    "#Replace with proper addresses of sampled data. Data used here was seperated by E4-carriers and E4-NCS\n",
    "#######\n",
    "E4_AD_data_fp=\"C:/Users/woods/OneDrive/Documents/Research/Brain Lab/brain age paper/Sampled Data/both_apoe4_ad.csv\"\n",
    "NC_AD_data_fp=\"C:/Users/woods/OneDrive/Documents/Research/Brain Lab/brain age paper/Sampled Data/both_nonapoe4_ad.csv\"\n",
    "CU_data_fp=\"C:/Users/woods/OneDrive/Documents/Research/Brain Lab/brain age paper/Sampled Data/sampled_cn2.csv\"\n",
    "\n",
    "apoe4_ad=pd.read_csv(E4_AD_data_fp).fillna(0)\n",
    "apoe4_ad['label']=pd.DataFrame(np.ones((apoe4_ad.shape[0])))\n",
    "apoe4_ad['APOE4']=1 #adds genotype information\n",
    "\n",
    "nonapoe4_ad=pd.read_csv(NC_AD_data_fp).fillna(0)\n",
    "nonapoe4_ad['label']=pd.DataFrame(np.zeros((nonapoe4_ad.shape[0])))\n",
    "nonapoe4_ad['APOE4']=0 #adds genotype information\n",
    "\n",
    "data_cn=pd.read_csv(CU_data_fp)#already gentically labeled\n",
    "#sort by genetic labels\n",
    "apoe4_cn=data_cn[data_cn['APOE4']==1]\n",
    "nonapoe4_cn=data_cn[data_cn['APOE4']==0] \n",
    "\n",
    "\n",
    "features = [ \"CBTIA_1.0\", \"DEP2YRS_1.0\", \"DIABETES_1.0\", \"SOMATIC_1.0\", \"NACCBMI\",\"INCONTU_1.0\",\"EDUC\",\n",
    "          \"B12DEF_2.0\", \"BPDIAS\", \"BPSYS\", \"HRATE\", \"SMOKYRS\", \"VISWCORR_1.0\", \"B12DEF_1.0\", \"NACCBETA_1.0\", \n",
    "         \"NACCLIPL_1.0\", \"NACCDBMD_1.0\", \"SEX\",'APOE4']\n",
    "\n",
    "brain = [\"NACCAGE\", \"CEREALL\", \"CERECSF\", \"CEREGR\", \"CERETISS\", \"CEREWH\", \"CSFVOL\", \"FRCORT\", \"GRAYVOL\", \"HIPPOVOL\", \"LATVENT\",\n",
    "        \"LCAC\", \"LCACM\", \"LCMF\", \"LCMFM\", \"LCUN\", \"LCUNM\", \"LENT\", \"LENTM\", \"LFRCORT\", \"LFUS\", \"LFUSM\", \"LHIPPO\", \"LINFPAR\",\n",
    "        \"LINFPARM\", \"LINFTEMM\", \"LINFTEMP\", \"LINSULA\",\"LINSULAM\",\"LISTHC\",\"LISTHCM\",\"LLATOCC\",\"LLATOCCM\",\"LLATORBF\",\n",
    "        \"LLATORBM\",\"LLATVENT\",\"LLING\",\"LLINGM\",\"LMEDORBF\",\"LMEDORBM\",\"LMIDTEMM\",\"LMIDTEMP\", \"LOCCORT\",\"LPARCEN\",\"LPARCENM\",\n",
    "        \"LPARCORT\", \"LPARHIP\", \"LPARHIPM\", \"LPARORB\", \"LPARORBM\", \"LPARSOP\", \"LPARSOPM\", \"LPARTRI\", \"LPARTRIM\", \"LPERCAL\",\n",
    "        \"LPERCALM\", \"LPOSCEN\", \"LPOSCENM\", \"LPOSCIN\", \"LPOSCINM\", \"LPRECEN\", \"LPRECENM\", \"LPRECUN\", \"LPRECUNM\", \"LROSANC\",\n",
    "        \"LROSANCM\", \"LROSMF\", \"LROSMFM\", \"LSUPFR\", \"LSUPFRM\", \"LSUPMAR\", \"LSUPMARM\", \"LSUPPAR\", \"LSUPPARM\", \"LSUPTEM\", \"LSUPTEMM\",\n",
    "        \"LTEMPCOR\", \"LTRTEM\", \"LTRTEMM\", \"NACCBRNV\", \"NACCICV\", \"NACCWMVL\", \"OCCCORT\", \"PARCORT\", \"RCAC\", \"RCACM\",\n",
    "        \"RCMF\", \"RCMFM\", \"RCUN\", \"RCUNM\", \"RENT\", \"RENTM\", \"RFRCORT\", \"RFUS\", \"RFUSM\", \"RHIPPO\", \"RINFPAR\", \"RINFPARM\",\n",
    "        \"RINFTEMM\", \"RINFTEMP\", \"RINSULA\", \"RINSULAM\", \"RISTHC\", \"RISTHCM\", \"RLATOCC\", \"RLATOCCM\", \"RLATORBF\", \"RLATORBM\",\n",
    "        \"RLATVENT\", \"RLING\", \"RLINGM\", \"RMEDORBF\", \"RMEDORBM\", \"RMIDTEMM\", \"RMIDTEMP\", \"ROCCORT\", \"RPARCEN\", \"RPARCENM\",\n",
    "        \"RPARCORT\", \"RPARHIP\", \"RPARHIPM\", \"RPARORB\", \"RPARORBM\", \"RPARSOP\", \"RPARSOPM\", \"RPARTRI\", \"RPARTRIM\", \"RPERCAL\",\n",
    "        \"RPERCALM\", \"RPOSCEN\", \"RPOSCENM\", \"RPOSCIN\", \"RPOSCINM\", \"RPRECEN\", \"RPRECENM\", \"RPRECUN\", \"RPRECUNM\", \"RROSANC\",\n",
    "        \"RROSANCM\", \"RROSMF\", \"RROSMFM\", \"RSUPFR\", \"RSUPFRM\", \"RSUPMAR\", \"RSUPMARM\", \"RSUPPAR\", \"RSUPPARM\", \"RSUPTEM\", \n",
    "        \"RSUPTEMM\", \"RTEMPCOR\", \"RTRTEM\", \"RTRTEMM\", \"TEMPCOR\", \"THIRVENT\", \"WHITEVOL\", \"WMHVOL\"]\n",
    "\n",
    "all_features=brain+features\n",
    "\n",
    "data_cn=data_cn[all_features]\n",
    "\n",
    "########################Set data to features for APOE4 groups###########\n",
    "apoe4_cn=apoe4_cn[all_features]\n",
    "nonapoe4_cn=nonapoe4_cn[all_features]\n",
    "apoe4_ad=apoe4_ad[all_features]\n",
    "nonapoe4_ad=nonapoe4_ad[all_features]\n",
    "\n",
    "\n",
    "\n",
    "########################Set data to features for Gender groups###########\n",
    "data_cn=data_cn[all_features]\n",
    "data_cn_MALE=data_cn[data_cn['SEX']==1]\n",
    "data_cn_FEMALE=data_cn[data_cn['SEX']==2]\n",
    "########################################################################\n",
    "\n",
    "###########Seperate target variables #############\n",
    "x_all_cu=data_cn.drop([\"NACCAGE\"], axis=1)\n",
    "y_all_cu=data_cn.NACCAGE\n",
    "\n",
    "x_apoe4_cu=apoe4_cn.drop([\"NACCAGE\"], axis=1)\n",
    "y_apoe4_cu=apoe4_cn.NACCAGE\n",
    "x_non_cu=nonapoe4_cn.drop([\"NACCAGE\"], axis=1)\n",
    "y_non_cu=nonapoe4_cn.NACCAGE\n",
    "\n",
    "data_apoe4_ad=apoe4_ad[apoe4_ad.NACCAGE<top_age]\n",
    "data_non_ad=nonapoe4_ad[nonapoe4_ad.NACCAGE<top_age]\n",
    "########################################################################################\n",
    "ad_data_all=pd.concat([data_apoe4_ad,data_non_ad])#####################################\n",
    "\n",
    "#########################################################################################\n",
    "x_apoe4_ad=data_apoe4_ad.drop([\"NACCAGE\"], axis=1)\n",
    "y_apoe4_ad=data_apoe4_ad.NACCAGE\n",
    "\n",
    "x_non_ad=data_non_ad.drop([\"NACCAGE\"], axis=1)\n",
    "y_non_ad=data_non_ad.NACCAGE\n",
    "\n",
    "x_all_ad=ad_data_all.drop([\"NACCAGE\"],axis=1)\n",
    "y_all_ad=ad_data_all.NACCAGE\n",
    "####################################################\n",
    "\n",
    "\n",
    "#######For generating gender seperated data#############\n",
    "\n",
    "data_ad_MALE=ad_data_all[ad_data_all['SEX']==1]\n",
    "data_ad_FEMALE=ad_data_all[ad_data_all['SEX']==2]\n",
    "\n",
    "data_ad1=data_ad_MALE[data_ad_MALE.NACCAGE<top_age]#\n",
    "data_ad2=data_ad_FEMALE[data_ad_FEMALE.NACCAGE<top_age]#\n",
    "\n",
    "x_male=data_cn_MALE.drop([\"NACCAGE\"], axis=1)\n",
    "y_male=data_cn_MALE.NACCAGE\n",
    "\n",
    "x_female=data_cn_FEMALE.drop([\"NACCAGE\"], axis=1)\n",
    "y_female=data_cn_FEMALE.NACCAGE\n",
    "\n",
    "x_ad_male=data_ad1.drop([\"NACCAGE\"], axis=1)\n",
    "y_ad_male=data_ad1.NACCAGE\n",
    "\n",
    "x_ad_female=data_ad2.drop([\"NACCAGE\"], axis=1)\n",
    "y_ad_female=data_ad2.NACCAGE\n",
    "#########################################################\n",
    "\n",
    "############## For groups D and E (APOE4 COMPARISON)#######################\n",
    "target_length_D=round(len(x_apoe4_cu)/2)\n",
    "target_length_E_E4=round(len(x_apoe4_cu))\n",
    "target_length_E_NC=round(len(x_non_cu)/2+((len(x_non_cu)/2)-len(x_apoe4_cu)))#to correct for lack of CU APOE4 samples\n",
    "\n",
    "indices_to_keep_D_e4=np.random.choice(len(x_apoe4_cu),target_length_D,replace=False)\n",
    "indices_to_keep_D_NC=np.random.choice(len(x_non_cu),target_length_D,replace=False)\n",
    "\n",
    "x_group_D_cu=pd.concat([x_apoe4_cu.iloc[indices_to_keep_D_e4],x_non_cu.iloc[indices_to_keep_D_NC]],axis=0)\n",
    "y_group_D_cu=pd.concat([y_apoe4_cu.iloc[indices_to_keep_D_e4],y_non_cu.iloc[indices_to_keep_D_NC]],axis=0)\n",
    "\n",
    "indices_to_keep_E_e4=np.random.choice(len(x_apoe4_cu),target_length_E_E4,replace=False)\n",
    "indices_to_keep_E_NC=np.random.choice(len(x_non_cu),target_length_E_NC,replace=False)\n",
    "x_group_E_cu=pd.concat([x_apoe4_cu.iloc[indices_to_keep_E_e4],x_non_cu.iloc[indices_to_keep_E_NC]],axis=0)\n",
    "y_group_E_cu=pd.concat([y_apoe4_cu.iloc[indices_to_keep_E_e4],y_non_cu.iloc[indices_to_keep_E_NC]],axis=0)\n",
    "###########################################################################\n",
    "\n",
    "############## For groups D and E (APOE4 COMPARISON)#######################\n",
    "\n",
    "target_length_E_E4=round(len(x_apoe4_cu))\n",
    "target_length_E_NC=round(len(x_non_cu)/2+((len(x_non_cu)/2)-len(x_apoe4_cu)))#to correct for lack of CU APOE4 samples\n",
    "\n",
    "indices_to_keep_D_e4=np.random.choice(len(x_apoe4_cu),target_length_D,replace=False)\n",
    "indices_to_keep_D_NC=np.random.choice(len(x_non_cu),target_length_D,replace=False)\n",
    "x_group_D_cu=pd.concat([x_apoe4_cu.iloc[indices_to_keep_D_e4],x_non_cu.iloc[indices_to_keep_D_NC]],axis=0)\n",
    "y_group_D_cu=pd.concat([y_apoe4_cu.iloc[indices_to_keep_D_e4],y_non_cu.iloc[indices_to_keep_D_NC]],axis=0)\n",
    "\n",
    "indices_to_keep_E_e4=np.random.choice(len(x_apoe4_cu),target_length_E_E4,replace=False)\n",
    "indices_to_keep_E_NC=np.random.choice(len(x_non_cu),target_length_E_NC,replace=False)\n",
    "x_group_E_cu=pd.concat([x_apoe4_cu.iloc[indices_to_keep_E_e4],x_non_cu.iloc[indices_to_keep_E_NC]],axis=0)\n",
    "y_group_E_cu=pd.concat([y_apoe4_cu.iloc[indices_to_keep_E_e4],y_non_cu.iloc[indices_to_keep_E_NC]],axis=0)\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)#9999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f41ecd",
   "metadata": {},
   "source": [
    "APOE4 Specific Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14444acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the data structures used in cross validation, structures of _x subgroups are unnceassary and test on the opposite APOE4 genotype of the training group.\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "Num_models=25\n",
    "\n",
    "\n",
    "split_indices_A = list(cv.split(x_apoe4_cu))\n",
    "split_indices_B = list(cv.split(x_non_cu))\n",
    "split_indices_C=list(cv.split(x_all_cu))\n",
    "split_indices_D=list(cv.split(x_group_D_cu))\n",
    "split_indices_E=list(cv.split(x_group_E_cu))\n",
    "\n",
    "all_split_indices=[split_indices_A,split_indices_B,split_indices_C,split_indices_D,split_indices_E]\n",
    "ave_result_cu_A = []\n",
    "ave_result_ad_A = []\n",
    "\n",
    "ave_result_cu_B = []\n",
    "ave_result_ad_B = []\n",
    "\n",
    "ave_result_cu_C_e4 = []\n",
    "ave_result_ad_C_e4 = []\n",
    "ave_result_cu_C_nc = []\n",
    "ave_result_ad_C_nc = []\n",
    "\n",
    "ave_result_cu_D_e4 = []\n",
    "ave_result_cu_D_nc = []\n",
    "ave_result_ad_D_e4 = []\n",
    "ave_result_ad_D_nc = []\n",
    "\n",
    "ave_result_cu_E_e4 = []\n",
    "ave_result_cu_E_nc = []\n",
    "ave_result_ad_E_e4 = []\n",
    "ave_result_ad_E_nc = []\n",
    "\n",
    "'''ave_result_cu_A_x = []\n",
    "ave_result_cu_A_x = []\n",
    "ave_result_ad_A_x = []\n",
    "ave_result_ad_B_x = []'''\n",
    "\n",
    "# Array of smooth predictions\n",
    "ave_result_array = [\n",
    "    ave_result_cu_A,\n",
    "    ave_result_cu_B,\n",
    "    ave_result_cu_C_e4,\n",
    "    ave_result_cu_C_nc,\n",
    "    ave_result_cu_D_e4,\n",
    "    ave_result_cu_D_nc,\n",
    "    ave_result_cu_E_e4,\n",
    "    ave_result_cu_E_nc,\n",
    "    ave_result_ad_A,\n",
    "    ave_result_ad_B,\n",
    "    ave_result_ad_C_e4,\n",
    "    ave_result_ad_C_nc,\n",
    "    ave_result_ad_D_e4,\n",
    "    ave_result_ad_D_nc,\n",
    "    ave_result_ad_E_e4,\n",
    "    ave_result_ad_E_nc,\n",
    "\n",
    "    '''ave_result_cu_A_x,\n",
    "    ave_result_cu_A_x,\n",
    "    ave_result_ad_A_x,\n",
    "    ave_result_ad_B_x'''\n",
    "]\n",
    "####################################\n",
    "\n",
    "smooth_rl_vals_cu_A = []\n",
    "smooth_rl_vals_ad_A = []\n",
    "\n",
    "smooth_rl_vals_cu_B = []\n",
    "smooth_rl_vals_ad_B = []\n",
    "\n",
    "smooth_rl_vals_cu_C_e4 = []\n",
    "smooth_rl_vals_ad_C_e4 = []\n",
    "smooth_rl_vals_cu_C_nc = []\n",
    "smooth_rl_vals_ad_C_nc = []\n",
    "\n",
    "smooth_rl_vals_cu_D_e4 = []\n",
    "smooth_rl_vals_cu_D_nc = []\n",
    "smooth_rl_vals_ad_D_e4 = []\n",
    "smooth_rl_vals_ad_D_nc = []\n",
    "\n",
    "smooth_rl_vals_cu_E_e4 = []\n",
    "smooth_rl_vals_cu_E_nc = []\n",
    "smooth_rl_vals_ad_E_e4 = []\n",
    "smooth_rl_vals_ad_E_nc = []\n",
    "\n",
    "smooth_rl_vals_cu_A_e4 = []\n",
    "smooth_rl_vals_ad_A_nc = []\n",
    "smooth_rl_vals_cu_B_e4 = []\n",
    "smooth_rl_vals_ad_B_nc = []\n",
    "\n",
    "'''smooth_rl_vals_cu_A_x=[]\n",
    "smooth_rl_vals_cu_B_x=[]\n",
    "smooth_rl_vals_ad_A_x=[]\n",
    "smooth_rl_vals_ad_B_x=[]'''\n",
    "\n",
    "\n",
    "smooth_rl_vals_array = [\n",
    "    smooth_rl_vals_cu_A,\n",
    "    smooth_rl_vals_cu_B,\n",
    "    smooth_rl_vals_cu_C_e4,\n",
    "    smooth_rl_vals_cu_C_nc,\n",
    "    smooth_rl_vals_cu_D_e4,\n",
    "    smooth_rl_vals_cu_D_nc,\n",
    "    smooth_rl_vals_cu_E_e4,\n",
    "    smooth_rl_vals_cu_E_nc,\n",
    "    smooth_rl_vals_ad_A,\n",
    "    smooth_rl_vals_ad_B,\n",
    "    smooth_rl_vals_ad_C_e4,\n",
    "    smooth_rl_vals_ad_C_nc,\n",
    "    smooth_rl_vals_ad_D_e4,\n",
    "    smooth_rl_vals_ad_D_nc,\n",
    "    smooth_rl_vals_ad_E_e4,\n",
    "    smooth_rl_vals_ad_E_nc,\n",
    "    '''smooth_rl_vals_cu_A_x,\n",
    "    smooth_rl_vals_cu_B_x,\n",
    "    smooth_rl_vals_ad_A_x,\n",
    "    smooth_rl_vals_ad_B_x,'''\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "##################################\n",
    "##################################\n",
    "\n",
    "smooth_preds_cu_A = []\n",
    "smooth_preds_ad_A = []\n",
    "\n",
    "smooth_preds_cu_B = []\n",
    "smooth_preds_ad_B = []\n",
    "\n",
    "smooth_preds_cu_C_e4 = []\n",
    "smooth_preds_ad_C_e4 = []\n",
    "smooth_preds_cu_C_nc = []\n",
    "smooth_preds_ad_C_nc = []\n",
    "\n",
    "smooth_preds_cu_D_e4 = []\n",
    "smooth_preds_cu_D_nc = []\n",
    "smooth_preds_ad_D_e4 = []\n",
    "smooth_preds_ad_D_nc = []\n",
    "\n",
    "smooth_preds_cu_E_e4 = []\n",
    "smooth_preds_cu_E_nc = []\n",
    "smooth_preds_ad_E_e4 = []\n",
    "smooth_preds_ad_E_nc = []\n",
    "\n",
    "'''smooth_preds_cu_A_x = []\n",
    "smooth_preds_cu_B_x = []\n",
    "smooth_preds_ad_A_x = []\n",
    "smooth_preds_ad_B_x = []'''\n",
    "\n",
    "# Array of smooth predictions, change size to 20 if including_x groups\n",
    "smooth_preds_array = np.empty(20, dtype=object)\n",
    "\n",
    "###############################\n",
    "###############################\n",
    "\n",
    "smooth_preds_cu_list_A = []\n",
    "smooth_preds_cu_list_B = []\n",
    "smooth_preds_cu_list_C_e4 = []\n",
    "smooth_preds_cu_list_C_nc = []\n",
    "smooth_preds_cu_list_D_e4 = []\n",
    "smooth_preds_cu_list_D_NC = []\n",
    "smooth_preds_cu_list_E_e4 = []\n",
    "smooth_preds_cu_list_E_NC = []\n",
    "\n",
    "smooth_preds_ad_list_A = []\n",
    "smooth_preds_ad_list_B = []\n",
    "smooth_preds_ad_list_C_e4 = []\n",
    "smooth_preds_ad_list_C_nc = []\n",
    "smooth_preds_ad_list_D_e4 = []\n",
    "smooth_preds_ad_list_D_NC = []\n",
    "smooth_preds_ad_list_E_e4 = []\n",
    "smooth_preds_ad_list_E_NC = []\n",
    "\n",
    "'''smooth_preds_cu_list_A_x = []\n",
    "smooth_preds_ad_list_A_x = []\n",
    "smooth_preds_cu_list_B_x = []\n",
    "smooth_preds_ad_list_B_x = []'''\n",
    "\n",
    "# Array of smooth predictions lists\n",
    "\n",
    "ensemble_predictions_cu_A = []\n",
    "ensemble_predictions_ad_A = []\n",
    "\n",
    "ensemble_predictions_cu_B = []\n",
    "ensemble_predictions_ad_B = []\n",
    "\n",
    "ensemble_predictions_cu_C_e4 = []\n",
    "ensemble_predictions_ad_C_e4 = []\n",
    "ensemble_predictions_cu_C_nc = []\n",
    "ensemble_predictions_ad_C_nc = []\n",
    "\n",
    "ensemble_predictions_cu_D_e4 = []\n",
    "ensemble_predictions_cu_D_nc = []\n",
    "ensemble_predictions_ad_D_e4 = []\n",
    "ensemble_predictions_ad_D_nc = []\n",
    "\n",
    "ensemble_predictions_cu_E_e4 = []\n",
    "ensemble_predictions_cu_E_nc = []\n",
    "ensemble_predictions_ad_E_e4 = []\n",
    "ensemble_predictions_ad_E_nc = []\n",
    "'''ensemble_predictions_cu_A_x = []\n",
    "ensemble_predictions_ad_A_x = []\n",
    "ensemble_predictions_cu_A_x = []\n",
    "ensemble_predictions_ad_B_x = []'''\n",
    "\n",
    "\n",
    "# Array of smooth predictions lists\n",
    "smooth_preds_lists_array = np.empty((Num_models,20),dtype=object)\n",
    "################################\n",
    "for i in range(Num_models):\n",
    "    ################################\n",
    "\n",
    "    ###################################\n",
    "\n",
    "    ##################################\n",
    "    ensemble_predictions_cu_A = []\n",
    "    ensemble_predictions_ad_A = []\n",
    "\n",
    "    ensemble_predictions_cu_B = []\n",
    "    ensemble_predictions_ad_B = []\n",
    "\n",
    "    ensemble_predictions_cu_C_e4 = []\n",
    "    ensemble_predictions_ad_C_e4 = []\n",
    "    ensemble_predictions_cu_C_nc = []\n",
    "    ensemble_predictions_ad_C_nc = []\n",
    "\n",
    "    ensemble_predictions_cu_D_e4 = []\n",
    "    ensemble_predictions_cu_D_nc = []\n",
    "    ensemble_predictions_ad_D_e4 = []\n",
    "    ensemble_predictions_ad_D_nc = []\n",
    "\n",
    "    ensemble_predictions_cu_E_e4 = []\n",
    "    ensemble_predictions_cu_E_nc = []\n",
    "    ensemble_predictions_ad_E_e4 = []\n",
    "    ensemble_predictions_ad_E_nc = []\n",
    "\n",
    "    '''ensemble_predictions_cu_A_x = []\n",
    "    ensemble_predictions_cu_B_x = []\n",
    "    ensemble_predictions_ad_A_x = []\n",
    "    ensemble_predictions_ad_B_x = []'''\n",
    "    # Define real values lists for each category\n",
    "\n",
    "    real_vals_cu_A = []\n",
    "    real_vals_cu_B = []\n",
    "    real_vals_ad_A = []\n",
    "    real_vals_ad_B = []\n",
    "\n",
    "    real_vals_cu_C_e4 = []\n",
    "    real_vals_cu_C_NC = []\n",
    "    real_vals_ad_C_e4 = []\n",
    "    real_vals_ad_C_NC = []\n",
    "\n",
    "    real_vals_cu_D_e4 = []\n",
    "    real_vals_cu_D_NC = []\n",
    "    real_vals_ad_D_e4 = []\n",
    "    real_vals_ad_D_NC = []\n",
    "\n",
    "    real_vals_cu_E_e4 = []\n",
    "    real_vals_cu_E_NC = []\n",
    "    real_vals_ad_E_e4 = []\n",
    "    real_vals_ad_E_NC = []\n",
    "\n",
    "    '''real_vals_cu_A_x = []\n",
    "    real_vals_cu_B_x = []\n",
    "    real_vals_ad_A_x = []\n",
    "    real_vals_ad_B_x = []'''\n",
    "\n",
    "    # Array of real values lists\n",
    "\n",
    "#################################### Training sector #######################################################################\n",
    "    model=RandomForestRegressor(n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features='sqrt', max_depth=30)\n",
    "\n",
    "    for split_group_num, split_indices in enumerate(all_split_indices):\n",
    "        for fold_num, (train_index, test_index) in enumerate(split_indices):\n",
    "            print(split_group_num)\n",
    "            if split_group_num==0:#A\n",
    "                x_cn=x_apoe4_cu\n",
    "                y_cn=y_apoe4_cu\n",
    "                x_ad=x_apoe4_ad\n",
    "            if split_group_num==1:#B\n",
    "                x_cn=x_non_cu\n",
    "                y_cn=y_non_cu\n",
    "                x_ad=x_non_ad\n",
    "            if split_group_num==2:#C\n",
    "                x_cn=x_all_cu\n",
    "                y_cn=y_all_cu\n",
    "\n",
    "                x_ad_e4=x_apoe4_cu\n",
    "                x_ad_nc=x_apoe4_ad\n",
    "            if split_group_num==3:#D\n",
    "                x_cn=x_group_D_cu\n",
    "                y_cn=y_group_D_cu\n",
    "                x_ad=x_apoe4_cu\n",
    "            if split_group_num==4:#E\n",
    "                x_cn=x_group_E_cu\n",
    "                y_cn=y_group_E_cu\n",
    "                x_ad=x_non_ad\n",
    "            x_cn = pd.DataFrame(x_cn)\n",
    "            y_cn = pd.DataFrame(y_cn)\n",
    "            x_ad = pd.DataFrame(x_ad)\n",
    "            y_all_ad=pd.DataFrame(y_all_ad)\n",
    "            print(\"split group num=\",split_group_num)\n",
    "\n",
    "            x_train, x_test = x_cn.iloc[train_index], x_cn.iloc[test_index]\n",
    "            y_train, y_test = y_cn.iloc[train_index], y_cn.iloc[test_index]\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "            print('model fitting')\n",
    "            print('length of x_train=',len(x_train))\n",
    "            print('length of x_train apoe4=',len(x_train[x_train['APOE4']==1]))\n",
    "            [x_test['APOE4']==1]\n",
    "            print(len(x_train))\n",
    "            print(len(x_train))\n",
    "            model.fit(x_train, y_train)\n",
    "            print('fitting complete')\n",
    "###############################################################################################################\n",
    "            x_cn = pd.DataFrame(x_cn)\n",
    "            y_cn = pd.DataFrame(y_cn)\n",
    "            x_ad = pd.DataFrame(x_ad)\n",
    "############################################ Testing for each groups      #####################################\n",
    "            if (split_group_num==0):# Group A\n",
    "                y_pred_cu_A=model.predict(x_test)\n",
    "                y_pred_ad_A=model.predict(x_apoe4_ad)\n",
    "                ensemble_predictions_cu_A.append(y_pred_cu_A)\n",
    "                ensemble_predictions_ad_A.append(y_pred_ad_A)\n",
    "                real_vals_cu_A.append(y_test)\n",
    "                real_vals_ad_A.append(y_all_ad[x_all_ad['APOE4']==1])\n",
    "\n",
    "                '''y_pred_cu_A_x=model.predict(x_non_cu)\n",
    "                y_pred_ad_A_x=model.predict(x_non_ad)\n",
    "                ensemble_predictions_cu_A_x.append(y_pred_cu_A_x)\n",
    "                ensemble_predictions_ad_A_x.append(y_pred_ad_A_x)\n",
    "                real_vals_cu_A_x.append(y_non_cu)\n",
    "                real_vals_ad_A_x.append(y_all_ad[x_all_ad['APOE4']==0])'''\n",
    "\n",
    "            if (split_group_num==1):#Group B\n",
    "                y_pred_cu_B=model.predict(x_test)\n",
    "                y_pred_ad_B=model.predict(x_non_ad)\n",
    "                ensemble_predictions_cu_B.append(y_pred_cu_B)\n",
    "                ensemble_predictions_ad_B.append(y_pred_ad_B)\n",
    "                real_vals_cu_B.append(y_test)\n",
    "                real_vals_ad_B.append(y_all_ad[x_all_ad['APOE4']==0])\n",
    "\n",
    "                '''y_pred_cu_B_x=model.predict(x_apoe4_cu)\n",
    "                y_pred_ad_B_x=model.predict(x_apoe4_ad)\n",
    "                ensemble_predictions_cu_B_x.append(y_pred_cu_B_x)\n",
    "                ensemble_predictions_ad_B_x.append(y_pred_ad_B_x)\n",
    "                real_vals_cu_B_x.append(y_apoe4_cu)\n",
    "                real_vals_ad_B_x.append(y_all_ad[x_all_ad['APOE4']==1])'''\n",
    "            \n",
    "            if (split_group_num==2):#Group C\n",
    "                y_pred_cu_e4_C=model.predict(x_test[x_test['APOE4']==1])\n",
    "                y_pred_ad_e4_C=model.predict(x_all_ad[x_all_ad['APOE4']==1])\n",
    "                ensemble_predictions_cu_C_e4.append(y_pred_cu_e4_C)\n",
    "                ensemble_predictions_ad_C_e4.append(y_pred_ad_e4_C)\n",
    "                real_vals_cu_C_e4.append(y_test[x_test['APOE4']==1])\n",
    "                real_vals_ad_C_e4.append(y_all_ad[x_all_ad['APOE4']==1])\n",
    "\n",
    "                y_pred_cu_nc_C=model.predict(x_test[x_test['APOE4']==0])\n",
    "                y_pred_ad_nc_C=model.predict(x_all_ad[x_all_ad['APOE4']==0])\n",
    "                ensemble_predictions_cu_C_nc.append(y_pred_cu_nc_C)\n",
    "                ensemble_predictions_ad_C_nc.append(y_pred_ad_nc_C)\n",
    "                real_vals_cu_C_NC.append(y_test[x_test['APOE4']==0])\n",
    "                real_vals_ad_C_NC.append(y_all_ad[x_all_ad['APOE4']==0])\n",
    "\n",
    "            if (split_group_num==3):#Group D\n",
    "                y_pred_cu_D_e4=model.predict(x_test[x_test['APOE4']==1])\n",
    "                y_pred_ad_D_e4=model.predict(x_all_ad[x_all_ad['APOE4']==1])\n",
    "                ensemble_predictions_cu_D_e4.append(y_pred_cu_D_e4)\n",
    "                ensemble_predictions_ad_D_e4.append(y_pred_ad_D_e4)\n",
    "                real_vals_cu_D_e4.append(y_test[x_test['APOE4']==1])\n",
    "                real_vals_ad_D_e4.append(y_all_ad[x_all_ad['APOE4']==1])\n",
    "\n",
    "                y_pred_cu_D_nc=model.predict(x_test[x_test['APOE4']==0])\n",
    "                y_pred_ad_D_nc=model.predict(x_all_ad[x_all_ad['APOE4']==0])\n",
    "                ensemble_predictions_cu_D_nc.append(y_pred_cu_D_nc)\n",
    "                ensemble_predictions_ad_D_nc.append(y_pred_ad_D_nc)\n",
    "                real_vals_cu_D_NC.append(y_test[x_test['APOE4']==0])\n",
    "                real_vals_ad_D_NC.append(y_all_ad[x_all_ad['APOE4']==0])\n",
    "\n",
    "            if (split_group_num==4):#Group #\n",
    "                y_pred_cu_E_e4=model.predict(x_test[x_test['APOE4']==1])\n",
    "                y_pred_ad_E_e4=model.predict(x_all_ad[x_all_ad['APOE4']==1])\n",
    "                ensemble_predictions_cu_E_e4.append(y_pred_cu_E_e4)\n",
    "                ensemble_predictions_ad_E_e4.append(y_pred_ad_E_e4)\n",
    "                real_vals_cu_E_e4.append(y_test[x_test['APOE4']==1])\n",
    "                real_vals_ad_E_e4.append(y_all_ad[x_all_ad['APOE4']==1])\n",
    "\n",
    "                y_pred_cu_E_nc=model.predict(x_test[x_test['APOE4']==0])\n",
    "                y_pred_ad_E_nc=model.predict(x_all_ad[x_all_ad['APOE4']==0])\n",
    "                ensemble_predictions_cu_E_nc.append(y_pred_cu_E_nc)\n",
    "                ensemble_predictions_ad_E_nc.append(y_pred_ad_E_nc)\n",
    "                real_vals_cu_E_NC.append(y_test[x_test['APOE4']==0])\n",
    "                real_vals_ad_E_NC.append(y_all_ad[x_all_ad['APOE4']==0])\n",
    "##############################################################################################################\n",
    "    ensembled_preds_array = [\n",
    "    ensemble_predictions_cu_A,\n",
    "    ensemble_predictions_cu_B,\n",
    "    ensemble_predictions_cu_C_e4,\n",
    "    ensemble_predictions_cu_C_nc,\n",
    "    ensemble_predictions_cu_D_e4,   # New term\n",
    "    ensemble_predictions_cu_D_nc,   # New term\n",
    "    ensemble_predictions_cu_E_e4,   # New term\n",
    "    ensemble_predictions_cu_E_nc,   # New term\n",
    "    ensemble_predictions_ad_A,\n",
    "    ensemble_predictions_ad_B,\n",
    "    ensemble_predictions_ad_C_e4,\n",
    "    ensemble_predictions_ad_C_nc,\n",
    "    ensemble_predictions_ad_D_e4, \n",
    "    ensemble_predictions_ad_D_nc,   \n",
    "    ensemble_predictions_ad_E_e4,   \n",
    "    ensemble_predictions_ad_E_nc,\n",
    "\n",
    "    '''ensemble_predictions_cu_A_x,\n",
    "    ensemble_predictions_cu_B_x,\n",
    "    ensemble_predictions_ad_A_x,\n",
    "    ensemble_predictions_ad_B_x'''\n",
    "    \n",
    "    ]  \n",
    "\n",
    "    real_vals_array = [\n",
    "    real_vals_cu_A,\n",
    "    real_vals_cu_B,\n",
    "    real_vals_cu_C_e4,\n",
    "    real_vals_cu_C_NC,\n",
    "    real_vals_cu_D_e4,\n",
    "    real_vals_cu_D_NC,\n",
    "    real_vals_cu_E_e4,\n",
    "    real_vals_cu_E_NC,\n",
    "    real_vals_ad_A,\n",
    "    real_vals_ad_B,\n",
    "    real_vals_ad_C_e4,\n",
    "    real_vals_ad_C_NC,\n",
    "    real_vals_ad_D_e4,\n",
    "    real_vals_ad_D_NC,\n",
    "    real_vals_ad_E_e4,\n",
    "    real_vals_ad_E_NC,\n",
    "\n",
    "'''    real_vals_cu_A_x,\n",
    "    real_vals_cu_B_x,\n",
    "    real_vals_ad_A_x,\n",
    "    real_vals_ad_B_x'''\n",
    "    \n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "############################################ Ensembling Portion ##############################################\n",
    "\n",
    "    for j in range(20):#range is jsut size of all arrays.\n",
    "        print(j)\n",
    "        print(len(real_vals_array[j]))\n",
    "        smooth_rl_vals_array[j]=np.concatenate(real_vals_array[j])\n",
    "######################error above\n",
    "        if j<8:\n",
    "    \n",
    "            smooth_preds_array[j]=np.concatenate(ensembled_preds_array[j])\n",
    "        if j>=8:\n",
    "            smooth_preds_array[j]=np.mean(ensembled_preds_array[j],axis=0)\n",
    "        smooth_preds_lists_array[i][j]=(np.array(smooth_preds_array[j]))\n",
    "ave_result_array=np.mean(smooth_preds_lists_array,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e97160",
   "metadata": {},
   "source": [
    "Prepare data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e34986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(smooth_rl_vals_array)):\n",
    "    hold=smooth_rl_vals_array[i].flatten()\n",
    "    smooth_rl_vals_array[i]=hold\n",
    "\n",
    "smooth_rl_vals_cu_A = smooth_rl_vals_array[0]\n",
    "smooth_rl_vals_cu_B = smooth_rl_vals_array[1]\n",
    "\n",
    "smooth_rl_vals_cu_C_e4 = smooth_rl_vals_array[2]\n",
    "smooth_rl_vals_cu_C_nc = smooth_rl_vals_array[3]\n",
    "\n",
    "smooth_rl_vals_cu_D_e4 = smooth_rl_vals_array[4]\n",
    "smooth_rl_vals_cu_D_nc = smooth_rl_vals_array[5]\n",
    "\n",
    "\n",
    "smooth_rl_vals_cu_E_e4 = smooth_rl_vals_array[6]\n",
    "smooth_rl_vals_cu_E_nc = smooth_rl_vals_array[7]\n",
    "\n",
    "\n",
    "\n",
    "smooth_rl_vals_ad_A = smooth_rl_vals_array[8][:int(len(smooth_rl_vals_array[8]) / 5)]\n",
    "smooth_rl_vals_ad_B = smooth_rl_vals_array[9][:int(len(smooth_rl_vals_array[9]) / 5)]\n",
    "\n",
    "smooth_rl_vals_ad_C_e4 = smooth_rl_vals_array[10][:int(len(smooth_rl_vals_array[10]) / 5)]\n",
    "smooth_rl_vals_ad_C_nc = smooth_rl_vals_array[11][:int(len(smooth_rl_vals_array[11]) / 5)]\n",
    "\n",
    "smooth_rl_vals_ad_D_e4 = smooth_rl_vals_array[12][:int(len(smooth_rl_vals_array[12]) / 5)]\n",
    "smooth_rl_vals_ad_D_nc = smooth_rl_vals_array[13][:int(len(smooth_rl_vals_array[13]) / 5)]\n",
    "\n",
    "smooth_rl_vals_ad_E_e4 = smooth_rl_vals_array[14][:int(len(smooth_rl_vals_array[14]) / 5)]\n",
    "smooth_rl_vals_ad_E_nc = smooth_rl_vals_array[15][:int(len(smooth_rl_vals_array[15]) / 5)]\n",
    "\n",
    "'''smooth_rl_vals_cu_A_x = smooth_rl_vals_array[16][:int(len(smooth_rl_vals_array[16]) / 5)]\n",
    "smooth_rl_vals_cu_B_x = smooth_rl_vals_array[17][:int(len(smooth_rl_vals_array[17]) / 5)]\n",
    "smooth_rl_vals_ad_A_x = smooth_rl_vals_array[18][:int(len(smooth_rl_vals_array[18]) / 5)]\n",
    "smooth_rl_vals_ad_B_x = smooth_rl_vals_array[19][:int(len(smooth_rl_vals_array[19]) / 5)]'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "###########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ave_result_cu_A = ave_result_array[0] \n",
    "ave_result_cu_B = ave_result_array[1] \n",
    "\n",
    "ave_result_cu_C_e4 = ave_result_array[2]  \n",
    "ave_result_cu_C_nc = ave_result_array[3]\n",
    "\n",
    "ave_result_cu_D_e4 = ave_result_array[4] \n",
    "ave_result_cu_D_nc = ave_result_array[5]  \n",
    "\n",
    "ave_result_cu_E_e4 = ave_result_array[6] \n",
    "ave_result_cu_E_nc = ave_result_array[7]  \n",
    "\n",
    "ave_result_ad_A = ave_result_array[8] \n",
    "ave_result_ad_B = ave_result_array[9]  \n",
    "\n",
    "ave_result_ad_C_e4 = ave_result_array[10] \n",
    "ave_result_ad_C_nc = ave_result_array[11] \n",
    "\n",
    "ave_result_ad_D_e4 = ave_result_array[12] \n",
    "ave_result_ad_D_nc = ave_result_array[13] \n",
    "\n",
    "ave_result_ad_E_e4 = ave_result_array[14]\n",
    "ave_result_ad_E_nc = ave_result_array[15]  \n",
    "\n",
    "'''ave_result_cu_A_x = ave_result_array[16] \n",
    "ave_result_cu_B_x = ave_result_array[17] \n",
    "ave_result_ad_A_x = ave_result_array[18] \n",
    "ave_result_ad_B_x = ave_result_array[19] '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363454a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing sets\n",
    "###############################################################################################################################\n",
    "X_train_male, X_test_male, y_train_male, y_test_male = train_test_split(x_male, y_male, test_size=test_split, random_state=None)\n",
    "X_train_female, X_test_female, y_train_female, y_test_female = train_test_split(x_female, y_female, test_size=test_split, random_state=None)\n",
    "\n",
    "D_length=len(X_train_female)\n",
    "E_length=len(X_train_male)\n",
    "\n",
    "\n",
    "X_train_C= np.concatenate((X_train_male,X_train_female))\n",
    "y_train_C=np.concatenate((y_train_male,y_train_female))\n",
    "\n",
    "X_train_D=np.concatenate((X_train_male[:(math.floor(D_length/2))],X_train_female[:(math.floor(D_length/2))]))\n",
    "y_train_D=np.concatenate((y_train_male[:(math.floor(D_length/2))],y_train_female[:(math.floor(D_length/2))]))\n",
    "\n",
    "X_train_E= np.concatenate((X_train_male[:(math.floor(E_length/2))],X_train_female[:(math.floor(E_length/2))]))\n",
    "y_train_E=np.concatenate((y_train_male[:(math.floor(E_length/2))],y_train_female[:(math.floor(E_length/2))]))\n",
    "#########################################################################################################################################\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=800,min_samples_split=10,  min_samples_leaf=2, max_features='sqrt',max_depth=30)\n",
    "Num_models=250\n",
    "for iteration in range(Num_models):\n",
    "    ######################################################################\n",
    "\n",
    "    model.fit(X_train_male, y_train_male)\n",
    "    # make predictions on the testing data\n",
    "    y_pred_cn_A = model.predict(X_test_male)\n",
    "    ensemble_predictions_cn_male.append(y_pred_cn_A)\n",
    "\n",
    "    y_pred_ad1 = model.predict(x_ad_male)\n",
    "    ensemble_predictions_ad_male.append(y_pred_ad1)\n",
    "\n",
    "    ####################################################################\n",
    "    #SHAP, uncomment to save SHAP data\n",
    "    \n",
    "    '''  explainer = shap.Explainer(model)\n",
    "\n",
    "    shap_values_ml_cn = explainer(X_test_male)\n",
    "\n",
    "    SHAPsMale_cn.append(shap_values_ml_cn)\n",
    "   \n",
    "    shap_values_ml_ad = explainer(x_ad_male)\n",
    "    SHAPsMale_ad.append(shap_values_ml_cn)'''\n",
    "\n",
    "    ####        ####    ####\n",
    "    #Now non-APOE4  ####\n",
    "    ####        ####    ####\n",
    "        ########################################################################\n",
    "    model.fit(X_train_female, y_train_female)\n",
    "    \n",
    "    # make predictions on the testing data\n",
    "    y_pred_cn_B = model.predict(X_test_female)\n",
    "    ensemble_predictions_cn_female.append(y_pred_cn_B)\n",
    "\n",
    "    #####################\n",
    "    ####AD\n",
    "    #####################\n",
    "    y_pred_ad2 = model.predict(x_ad_female)\n",
    "    ensemble_predictions_ad_female.append(y_pred_ad2)\n",
    "    ########################################################################\n",
    "    \n",
    "    #######SHAP, uncomment to save SHAP data\n",
    "\n",
    "    '''   \n",
    "    explainer = shap.Explainer(model)\n",
    "    \n",
    "    shap_values_fm_cn = explainer(X_test_female)\n",
    "    SHAPsFemale_cn.append(shap_values_fm_cn)\n",
    "    \n",
    "    shap_values_fm_ad = explainer(x_ad_male)\n",
    "    SHAPsFemale_ad.append(shap_values_fm_ad)\n",
    "    '''\n",
    "\n",
    "#############################################################################\n",
    "    model.fit(X_train_C, y_train_C)\n",
    "\n",
    "    # make predictions on the testing data\n",
    "    y_pred_cn3 = model.predict(X_test_male)\n",
    "    ensemble_predictions_cn_male3.append(y_pred_cn3)\n",
    "\n",
    "    y_pred_ad3 = model.predict(x_ad_male)\n",
    "    ensemble_predictions_ad_male3.append(y_pred_ad3)\n",
    "   \n",
    "\n",
    "    y_pred_cn3_non = model.predict(X_test_female)\n",
    "    ensemble_predictions_cn_female3.append(y_pred_cn3_non)\n",
    "\n",
    "    y_pred_ad3_non = model.predict(x_ad_female)\n",
    "    ensemble_predictions_ad_female3.append(y_pred_ad3_non)\n",
    "###############################################################################\n",
    "\n",
    "    \n",
    "    ####################\n",
    "    #######SHAP,uncomment to save SHAP data\n",
    "    ####################\n",
    "    '''\n",
    "    explainer = shap.Explainer(model)\n",
    "    \n",
    "\n",
    "    shap_values_ml_cn3= explainer(X_test_male)\n",
    "    SHAPsMale_cn3.append(shap_values_ml_cn3)\n",
    "    shap_values_ml_ad3= explainer(x_ad_male)\n",
    "    SHAPsMale_ad3.append(shap_values_ml_ad3)\n",
    "\n",
    "\n",
    "    shap_values_fm_cn3= explainer(X_test_female)\n",
    "    SHAPsFemale_cn3.append(shap_values_fm_cn3)\n",
    "    shap_values_fm_ad3  = explainer(x_ad_female)\n",
    "    SHAPsFemale_ad3.append(shap_values_fm_ad3)\n",
    "    '''\n",
    "\n",
    "    #############################################################################\n",
    "    model.fit(X_train_D, y_train_D)\n",
    "\n",
    "    y_pred_cn_D = model.predict(X_test_female)\n",
    "    ensemble_predictions_cn_D_fm.append(y_pred_cn_D)\n",
    "\n",
    "    y_pred_ad_D = model.predict(x_ad_female)\n",
    "    ensemble_predictions_ad_D_fm.append(y_pred_ad_D)\n",
    "    #####################################################################################\n",
    "    model.fit(X_train_E, y_train_E)\n",
    "\n",
    "    y_pred_cn_E = model.predict(X_test_male)\n",
    "    ensemble_predictions_cn_E_ml.append(y_pred_cn_E)\n",
    "\n",
    "    y_pred_ad_E = model.predict(x_ad_male)\n",
    "    ensemble_predictions_ad_E_ml.append(y_pred_ad_E)\n",
    "    #####################################################################################\n",
    "    \n",
    "    ####################\n",
    "    #######SHAP, uncomment if collecting SHAP data\n",
    "    ####################\n",
    "    '''\n",
    "    explainer = shap.Explainer(model)\n",
    "    \n",
    "    \n",
    "    shap_values_ml_cn4= explainer(X_test_male)\n",
    "    SHAPsMale_cn4.append(shap_values_ml_cn4)\n",
    "    shap_values_ml_ad4= explainer(x_ad_male)\n",
    "    SHAPsMale_ad4.append(shap_values_ml_ad4)\n",
    "\n",
    "\n",
    "    shap_values_fm_cn4= explainer(X_test_female)\n",
    "    SHAPsFemale_cn4.append(shap_values_fm_cn4)\n",
    "    shap_values_fm_ad4  = explainer(x_ad_female)\n",
    "    SHAPsFemale_ad4.append(shap_values_fm_ad4)\n",
    "    '''\n",
    "    print(iteration)\n",
    "\n",
    "\n",
    "\n",
    "ave_ensemble_prediction_cn_fm = np.mean(ensemble_predictions_cn_female, axis=0)\n",
    "ave_ensemble_prediction_ad_fm = np.mean(ensemble_predictions_ad_female, axis=0)\n",
    "\n",
    "ave_ensemble_prediction_cn_ml = np.mean(ensemble_predictions_cn_male, axis=0)\n",
    "ave_ensemble_prediction_ad_ml = np.mean(ensemble_predictions_ad_male, axis=0)\n",
    "\n",
    "ave_ensemble_prediction_cn_C_fm = np.mean(ensemble_predictions_cn_female3, axis=0)\n",
    "ave_ensemble_prediction_ad_C_fm = np.mean(ensemble_predictions_ad_female3, axis=0)\n",
    "\n",
    "ave_ensemble_prediction_cn_C_ml = np.mean(ensemble_predictions_cn_male3, axis=0)\n",
    "ave_ensemble_prediction_ad_C_ml = np.mean(ensemble_predictions_ad_male3, axis=0)\n",
    "\n",
    "ave_ensemble_prediction_cn_D_ml = np.mean(ensemble_predictions_cn_D_fm, axis=0)\n",
    "ave_ensemble_prediction_ad_D_ml = np.mean(ensemble_predictions_ad_D_fm, axis=0)\n",
    "\n",
    "ave_ensemble_prediction_cn_E_fm = np.mean(ensemble_predictions_cn_E_ml, axis=0)\n",
    "ave_ensemble_prediction_ad_E_fm = np.mean(ensemble_predictions_ad_E_ml, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78270cb7",
   "metadata": {},
   "source": [
    "Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f5304ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace with your file path\n",
    "file_path = 'C:/Users/woods/OneDrive/Documents/Brain Lab/brain age paper/New code/risk_factor_APOE4'\n",
    "\n",
    "# Saving the NumPy arrays\n",
    "np.savetxt(f'{file_path}/ave_results_cn1.csv', ave_result_cu_A, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/ave_results_ad1.csv', ave_result_ad_A, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/ave_results_cn2.csv', ave_result_cu_B, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/ave_results_ad2.csv', ave_result_ad_B, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/ave_results_cn3_APOE4.csv', ave_result_cu_C_e4, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/ave_results_ad3_APOE4.csv', ave_result_ad_C_e4, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/ave_results_cn3_non.csv', ave_result_cu_C_nc, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/ave_results_ad3_non.csv', ave_result_ad_C_nc, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/ave_results_cn4_APOE4.csv', ave_result_cu_D_e4, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/ave_results_ad4_APOE4.csv', ave_result_ad_D_e4, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/ave_results_cn4_nc.csv', ave_result_cu_D_nc, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/ave_results_ad4_nc.csv', ave_result_ad_D_nc, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/ave_results_cn5_APOE4.csv', ave_result_cu_E_e4, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/ave_results_ad5_APOE4.csv', ave_result_ad_E_e4, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/ave_results_cn5_nc.csv', ave_result_cu_E_nc, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/ave_results_ad5_nc.csv', ave_result_ad_E_nc, delimiter=',', fmt='%f')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_cn1.csv', smooth_rl_vals_cu_A, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_ad1.csv', smooth_rl_vals_ad_A, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_cn2.csv', smooth_rl_vals_cu_B, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_ad2.csv', smooth_rl_vals_ad_B, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_cn3_APOE4.csv', smooth_rl_vals_cu_C_e4, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_ad3_APOE4.csv', smooth_rl_vals_ad_C_e4, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_cn3_non.csv', smooth_rl_vals_cu_C_nc, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_ad3_non.csv', smooth_rl_vals_ad_C_nc, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_cn4_APOE4.csv', smooth_rl_vals_cu_D_e4, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_ad4_APOE4.csv', smooth_rl_vals_ad_D_e4, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_cn4_nc.csv', smooth_rl_vals_cu_D_nc, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_ad4_nc.csv', smooth_rl_vals_ad_D_nc, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_cn5_APOE4.csv', smooth_rl_vals_cu_E_e4, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_ad5_APOE4.csv', smooth_rl_vals_ad_E_e4, delimiter=',', fmt='%f')\n",
    "\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_cn5_nc.csv', smooth_rl_vals_cu_E_nc, delimiter=',', fmt='%f')\n",
    "np.savetxt(f'{file_path}/smooth_rl_vals_ad5_nc.csv', smooth_rl_vals_ad_E_nc, delimiter=',', fmt='%f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d094bfcc",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace with your file path\n",
    "file_path = 'C:/Users/woods/OneDrive/Documents/Brain Lab/brain age paper/New code/risk_factor_APOE4'\n",
    "\n",
    "# Loading the NumPy arrays\n",
    "ave_result_cu_A = np.loadtxt(f'{file_path}/ave_results_cn1.csv', delimiter=',', dtype=int)\n",
    "ave_result_ad_A = np.loadtxt(f'{file_path}/ave_results_ad1.csv', delimiter=',', dtype=int)\n",
    "\n",
    "ave_result_cu_B = np.loadtxt(f'{file_path}/ave_results_cn2.csv', delimiter=',', dtype=int)\n",
    "ave_result_ad_B = np.loadtxt(f'{file_path}/ave_results_ad2.csv', delimiter=',', dtype=int)\n",
    "\n",
    "ave_result_cu_C_e4 = np.loadtxt(f'{file_path}/ave_results_cn3_APOE4.csv', delimiter=',', dtype=int)\n",
    "ave_result_ad_C_e4 = np.loadtxt(f'{file_path}/ave_results_ad3_APOE4.csv', delimiter=',', dtype=int)\n",
    "\n",
    "ave_result_cu_C_nc = np.loadtxt(f'{file_path}/ave_results_cn3_non.csv', delimiter=',', dtype=int)\n",
    "ave_result_ad_C_nc = np.loadtxt(f'{file_path}/ave_results_ad3_non.csv', delimiter=',', dtype=int)\n",
    "\n",
    "ave_result_cu_D_e4 = np.loadtxt(f'{file_path}/ave_results_cn4_APOE4.csv', delimiter=',', dtype=int)\n",
    "ave_result_ad_D_e4 = np.loadtxt(f'{file_path}/ave_results_ad4_APOE4.csv', delimiter=',', dtype=int)\n",
    "\n",
    "ave_result_cu_D_nc = np.loadtxt(f'{file_path}/ave_results_cn4_nc.csv', delimiter=',', dtype=int)\n",
    "ave_result_ad_D_nc = np.loadtxt(f'{file_path}/ave_results_ad4_nc.csv', delimiter=',', dtype=int)\n",
    "\n",
    "ave_result_cu_E_e4 = np.loadtxt(f'{file_path}/ave_results_cn5_APOE4.csv', delimiter=',', dtype=int)\n",
    "ave_result_ad_E_e4 = np.loadtxt(f'{file_path}/ave_results_ad5_APOE4.csv', delimiter=',', dtype=int)\n",
    "\n",
    "ave_result_cu_E_nc = np.loadtxt(f'{file_path}/ave_results_cn5_nc.csv', delimiter=',', dtype=int)\n",
    "ave_result_ad_E_nc = np.loadtxt(f'{file_path}/ave_results_ad5_nc.csv', delimiter=',', dtype=int)\n",
    "\n",
    "smooth_rl_vals_cu_A = np.loadtxt(f'{file_path}/smooth_rl_vals_cn1.csv', delimiter=',', dtype=int)\n",
    "smooth_rl_vals_ad_A = np.loadtxt(f'{file_path}/smooth_rl_vals_ad1.csv', delimiter=',', dtype=int)\n",
    "\n",
    "smooth_rl_vals_cu_B = np.loadtxt(f'{file_path}/smooth_rl_vals_cn2.csv', delimiter=',', dtype=int)\n",
    "smooth_rl_vals_ad_B = np.loadtxt(f'{file_path}/smooth_rl_vals_ad2.csv', delimiter=',', dtype=int)\n",
    "\n",
    "smooth_rl_vals_cu_C_e4 = np.loadtxt(f'{file_path}/smooth_rl_vals_cn3_APOE4.csv', delimiter=',', dtype=int)\n",
    "smooth_rl_vals_ad_C_e4 = np.loadtxt(f'{file_path}/smooth_rl_vals_ad3_APOE4.csv', delimiter=',', dtype=int)\n",
    "\n",
    "smooth_rl_vals_cu_C_nc = np.loadtxt(f'{file_path}/smooth_rl_vals_cn3_non.csv', delimiter=',', dtype=int)\n",
    "smooth_rl_vals_ad_C_nc = np.loadtxt(f'{file_path}/smooth_rl_vals_ad3_non.csv', delimiter=',', dtype=int)\n",
    "\n",
    "smooth_rl_vals_cu_D_e4 = np.loadtxt(f'{file_path}/smooth_rl_vals_cn4_APOE4.csv', delimiter=',', dtype=int)\n",
    "smooth_rl_vals_ad_D_e4 = np.loadtxt(f'{file_path}/smooth_rl_vals_ad4_APOE4.csv', delimiter=',', dtype=int)\n",
    "\n",
    "smooth_rl_vals_cu_D_nc = np.loadtxt(f'{file_path}/smooth_rl_vals_cn4_nc.csv', delimiter=',', dtype=int)\n",
    "smooth_rl_vals_ad_D_nc = np.loadtxt(f'{file_path}/smooth_rl_vals_ad4_nc.csv', delimiter=',', dtype=int)\n",
    "\n",
    "smooth_rl_vals_cu_E_e4 = np.loadtxt(f'{file_path}/smooth_rl_vals_cn5_APOE4.csv', delimiter=',', dtype=int)\n",
    "smooth_rl_vals_ad_E_e4 = np.loadtxt(f'{file_path}/smooth_rl_vals_ad5_APOE4.csv', delimiter=',', dtype=int)\n",
    "\n",
    "smooth_rl_vals_cu_E_nc = np.loadtxt(f'{file_path}/smooth_rl_vals_cn5_nc.csv', delimiter=',', dtype=int)\n",
    "smooth_rl_vals_ad_E_nc = np.loadtxt(f'{file_path}/smooth_rl_vals_ad5_nc.csv', delimiter=',', dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30898a08",
   "metadata": {},
   "source": [
    "Creating Scatter Plots and Calculating ID Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838205df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.integrate import quad\n",
    "import numpy as np\n",
    "\n",
    "#smooth_rl_vals_cu_A = np.array(smooth_rl_vals_cu_A)\n",
    "\n",
    "def line_of_best_fit(x, slope, intercept):\n",
    "    return slope * x + intercept\n",
    "\n",
    "def calculate_mae(y_true, y_pred, slope, intercept):\n",
    "    best_fit_vals = line_of_best_fit(y_true, slope, intercept)\n",
    "    return mean_absolute_error(y_pred, best_fit_vals)\n",
    "\n",
    "def integrand(x, a, b, c, d):\n",
    "    return (c * x + d) - (a * x + b)\n",
    "\n",
    "def plot_scatter_with_fit(y_true_cn, y_pred_cn, y_true_ad, y_pred_ad, x_label, y_label, group_label):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_true_cn, y_pred_cn, marker='o', label='CU',color='purple')\n",
    "    ax.scatter(y_true_ad, y_pred_ad, marker='^', label='AD',color='green')\n",
    "    ax.legend()\n",
    "    ax.plot([55, top_age], [55, top_age], linestyle='--', color='black')\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlim(55, top_age)\n",
    "    ax.set_ylim(55, 90)\n",
    "\n",
    "    unique_y_true_cn = np.unique(y_true_cn)\n",
    "    unique_y_true_ad = np.unique(y_true_ad)\n",
    "    ax.plot(unique_y_true_cn, np.poly1d(np.polyfit(y_true_cn, y_pred_cn, 1))(unique_y_true_cn), color='purple', label='Line of Best Fit (CU)')\n",
    "    ax.plot(unique_y_true_ad, np.poly1d(np.polyfit(y_true_ad, y_pred_ad, 1))(unique_y_true_ad), color='green', label='Line of Best Fit (AD)')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "def process_data(y_true_cn, y_pred_cn, y_true_ad, y_pred_ad, group_label):\n",
    "    plot_scatter_with_fit(y_true_cn, y_pred_cn, y_true_ad, y_pred_ad, 'Chronological Age', 'Brain Estimate Age', group_label)\n",
    "    \n",
    "    coefficients_cn = np.polyfit(y_true_cn, y_pred_cn, 1)\n",
    "    slope_cn, y_int_cn = coefficients_cn\n",
    "    coefficients_ad = np.polyfit(y_true_ad, y_pred_ad, 1)\n",
    "    slope_ad, y_int_ad = coefficients_ad\n",
    "\n",
    "    print(f\"Slope for CU {group_label}:\", (slope_cn),\"x+\",y_int_cn)\n",
    "    print(f\"Slope for AD {group_label}:\", (slope_ad),\"x+\",y_int_ad)\n",
    "\n",
    "    diff_factor, _ = quad(integrand, 55, top_age, args=(slope_cn, y_int_cn, slope_ad, y_int_ad))\n",
    "    print(f\"The BAD for {group_label} is:\", diff_factor/20)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def calculate_std(y_true, y_pred, slope, intercept):\n",
    "        # Calculate residuals\n",
    "        residuals = y_pred - (slope * y_true + intercept)\n",
    "        # Calculate standard deviation of residuals\n",
    "        std_dev = np.std(residuals)\n",
    "        return std_dev\n",
    "    mae_cn = calculate_mae(y_true_cn, y_pred_cn, slope_cn, y_int_cn)\n",
    "    mae_ad = calculate_mae(y_true_ad, y_pred_ad, slope_ad, y_int_ad)\n",
    "\n",
    "    cn_sigma = calculate_std(y_true_cn, y_pred_cn, slope_cn, y_int_cn)\n",
    "    ad_sigma = calculate_std(y_true_ad, y_pred_ad, slope_ad, y_int_ad)\n",
    "\n",
    "    print(f\"MAE for CU {group_label} line of best fit:\", mae_cn)\n",
    "    print(f\"MAE for AD {group_label} line of best fit:\", mae_ad)\n",
    "    \n",
    "    print(f\"Standard deviation for CU {group_label} line of best fit:\", cn_sigma)\n",
    "    print(f\"Standard deviation for AD {group_label} line of best fit:\", ad_sigma)\n",
    "\n",
    "\n",
    "    # Define the function for mu\n",
    "    def mu_function_cn(slope,t,cn_int):#this find the \"average\", or point on the LOBF\n",
    "        return slope * t + cn_int\n",
    "    def mu_function_ad(slope,t,ad_int):#this find the \"average\", or point on the LOBF\n",
    "        return slope * t + ad_int\n",
    "        \n",
    "\n",
    "        # Define the normal PDFs where mu is a function of t\n",
    "    def normal_pdf_cn(x, t, sigma,slope,int):\n",
    "            mu = mu_function_cn(slope,t,int)\n",
    "            return norm.pdf(x, mu, sigma)\n",
    "\n",
    "    def normal_pdf_ad(x, t, sigma,slope,int):\n",
    "        mu = mu_function_ad(slope,t,int)\n",
    "        return norm.pdf(x, mu, sigma)\n",
    "\n",
    "    def diff_at_point(x, t, cn_slope, ad_slope, cn_int, ad_int, cn_sigma, ad_sigma):\n",
    "        pdf_difference = abs(normal_pdf_cn(x, t, cn_sigma, cn_slope, cn_int) - normal_pdf_ad(x, t, ad_sigma, ad_slope, ad_int))\n",
    "        return pdf_difference\n",
    "    def integrate_diff_over_t(t):\n",
    "        a,b= quad(diff_at_point, -np.inf, np.inf, args=(t, slope_cn, slope_ad, y_int_cn, y_int_ad, cn_sigma, ad_sigma))\n",
    "        return a\n",
    "    t_min = 55\n",
    "    t_max = top_age\n",
    "\n",
    "    integrated_difference1, error = quad(integrate_diff_over_t, 55, 59)\n",
    "\n",
    "    integrated_difference2, error = quad(integrate_diff_over_t, 59, 63)\n",
    "    integrated_difference3, error = quad(integrate_diff_over_t, 63, 67)\n",
    "    integrated_difference4, error = quad(integrate_diff_over_t, 67, 71)\n",
    "    integrated_difference5, error = quad(integrate_diff_over_t, 71,75)\n",
    "    integrated_difference, error = quad(integrate_diff_over_t, 55, top_age)\n",
    "    \n",
    "    integrated_difference, error = quad(integrate_diff_over_t, t_min, t_max)\n",
    "    \n",
    "    print(\"ID value:\",(integrated_difference)/40)\n",
    "\n",
    "##################### Uncommment below sections for ID value of limited ranges. ##################\n",
    "    '''\n",
    "    print(\"IDV1:\",integrated_difference1/8)\n",
    "    print(\"IDV2:\",integrated_difference2/8)\n",
    "    print(\"IDV3:\",integrated_difference3/8)\n",
    "    print(\"IDV4:\",integrated_difference4/8)\n",
    "    print(\"IDV5:\",integrated_difference5/8)\n",
    "'''\n",
    "############################################################################################################################################################\n",
    "process_data(smooth_rl_vals_cu_A[smooth_rl_vals_cu_A<top_age] ,ave_result_cu_A[smooth_rl_vals_cu_A<top_age] ,               smooth_rl_vals_ad_A ,ave_result_ad_A,  'Model A APOE4')\n",
    "process_data(smooth_rl_vals_cu_B[smooth_rl_vals_cu_B<top_age] ,ave_result_cu_B[smooth_rl_vals_cu_B<top_age],                smooth_rl_vals_ad_B ,ave_result_ad_B,  'Model B non')\n",
    "\n",
    "process_data(smooth_rl_vals_cu_C_e4[smooth_rl_vals_cu_C_e4<top_age] ,ave_result_cu_C_e4[smooth_rl_vals_cu_C_e4<top_age],                smooth_rl_vals_ad_C_e4 ,ave_result_ad_C_e4,  'Model C APOE4')\n",
    "process_data(smooth_rl_vals_cu_C_nc[smooth_rl_vals_cu_C_nc<top_age] ,ave_result_cu_C_nc[smooth_rl_vals_cu_C_nc<top_age],                smooth_rl_vals_ad_C_nc ,ave_result_ad_C_nc,  'Model C non')\n",
    "\n",
    "process_data(smooth_rl_vals_cu_D_e4[smooth_rl_vals_cu_D_e4<top_age] ,ave_result_cu_D_e4[smooth_rl_vals_cu_D_e4<top_age],                smooth_rl_vals_ad_D_e4 ,ave_result_ad_D_e4,  'Model D APOE4')\n",
    "\n",
    "process_data(smooth_rl_vals_cu_D_nc[smooth_rl_vals_cu_D_nc<top_age] ,ave_result_cu_D_nc[smooth_rl_vals_cu_D_nc<top_age],                smooth_rl_vals_ad_D_nc ,ave_result_ad_D_nc,  'Model D non')\n",
    "\n",
    "process_data(smooth_rl_vals_cu_E_e4[smooth_rl_vals_cu_E_e4<top_age] ,ave_result_cu_E_e4[smooth_rl_vals_cu_E_e4<top_age],                smooth_rl_vals_ad_E_e4 ,ave_result_ad_E_e4,  'Model E APOE4')\n",
    "process_data(smooth_rl_vals_cu_E_nc[smooth_rl_vals_cu_E_nc<top_age] ,ave_result_cu_E_nc[smooth_rl_vals_cu_E_nc<top_age],                smooth_rl_vals_ad_E_nc ,ave_result_ad_E_nc,  'Model E non')\n",
    "##############################################################################################################################################################'''\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
